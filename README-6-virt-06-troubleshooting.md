# Домашнее задание к занятию "6.6. Troubleshooting"

## Задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её 
нужно прервать. 

Вы как инженер поддержки решили произвести данную операцию:
- напишите список операций, которые вы будете производить для остановки запроса пользователя

```bash
mongosh "mongodb:://localhost:27017" # если нет, то попробую поискать кастомеый порт --port и наличие mongodb, и наличие его на данном хосте

db # моя db

db.enableFreeMonitoring() #выведет время выполнения и использование памяти
db.disableFreeMonitoring() #выключу, чтобы не тратить ресурсы

#выполню 

db.currentOp({"secs_running":{$gte:5}})

#где, в выводе query - выполняемый запрос, active - выполняется сейчас, ns - коллекция, secs_running - с выполнения
#найду конкретный запрос, приводящий к "тормозам"

db.inventory.find (
    { quantity : {$gte: 100, $lte: 200} }
).explain("executionStats")


```

- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB

> В конфигурационном /etc/mongosh.cfg можно с настройками поработать: Например 

```bash

mongosh:
  historyLength: 700 # default 1000
  snippetAutoload: false # проверим не связано ли это с загруженными сниппетами
```

> Или тоже сделать в коммандной строке mongosh

```bash

config.set( "historyLength", 700 ) 
config.set( "snippetAutoload", false )

```

> Но скорее всего надо найти того, кто вызывает так часто CRUD и завершить выполнение и чрезмерное использование.


## Задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса. 

При масштабировании сервиса до N реплик вы увидели, что:
- сначала рост отношения записанных значений к истекшим
- Redis блокирует операции записи

Как вы думаете, в чем может быть проблема?

> Скорее всего из-за превышения порога по-умолчанию ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP = 10 в сек. Возможно, нужно пересмотреть это значение.

## Задача 3

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей, в таблицах базы,
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?

Какие пути решения данной проблемы вы можете предложить?

> Кроме того, что Postgresql справится лучше с таким объемом, можно включить slowlog:



```bash

#/etc/my.cnf

slow_query_log = 1
slow_query_log_file = /var/log/mysql_slow.log
long_query_time = 2
log_query_not_using_indexes

```

> просмотреть mysql_slow.log выяснить какие запрсы тормозят, так же можно сделать на них EXPLAIN
> в месте ...QUERY HERE... вероятно, может быть причина

> Попытаться устранить причину


## Задача 4


Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объемом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?

> Когда у сервера или процесса заканчивается память, надо ее добавить как быстрое решение (если возможно)
> И, аналогично, необходимо проанализировать, включив в конфиге slow.log, это тоже может быть причиной:

```bash

log_min_duration_statement = 5000 # свыше 5000 мс выолняемые запосы записываются в slow.log

```
> Так же можно испоьзовать EXPLAIN

Как бы вы решили данную проблему?

> Но можно и запретить oom-killer убивать процесс через:

```bash

sudo echo -100 > /proc/{id процесса postmaster}}/oom_score_adj

```

> Чем больше (-100), тем больше шансов, что процесс будет убит oom-killer при нехватке памяти

---

### Как cдавать задание

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
